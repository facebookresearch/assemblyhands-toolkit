# Copyright (c) Facebook, Inc. and its affiliates.
# All rights reserved.
#
# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.
#

import os
import cv2
import numpy as np
from PIL import Image
from src import cfg
from src.common.utils.transforms import (
    world2cam,
    cam2pixel,
    pixel2cam,
    world2cam_assemblyhands,
)
import random
import math


def load_img(path, order="RGB"):

    # load
    img = cv2.imread(path, cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)
    if not isinstance(img, np.ndarray):
        raise IOError("Fail to read %s" % path)

    if order == "RGB":
        img = img[:, :, ::-1].copy()

    img = img.astype(np.float32)
    return img


def update_params_after_crop(
    bbox,
    pts_2d,
    joint_world,
    joint_valid,
    retval_camera,
    img_size,
    dataset="assemblyhands",
):
    (img_h, img_w) = img_size
    x0, y0, w, h = bbox
    box_l = max(int(max(w, h)), 100)  # at least 100px
    x0 = int((x0 + (x0 + w)) * 0.5 - box_l * 0.5)
    y0 = int((y0 + (y0 + h)) * 0.5 - box_l * 0.5)
    x1, y1 = x0 + box_l, y0 + box_l

    # change coordinates
    bbox = [0, 0, box_l, box_l]
    pts_2d[:, 0] -= x0
    pts_2d[:, 1] -= y0
    # 2d visibility check
    joint_valid = joint_valid > 0 & (pts_2d[:, :2].max(axis=1) < box_l)
    joint_valid = joint_valid.astype(int)

    retval_camera.update_after_crop([x0, y0, x1, y1])

    campos, camrot, focal, princpt = retval_camera.get_params()
    if dataset == "assemblyhands":
        joint_cam = world2cam_assemblyhands(joint_world, camrot, campos)
    else:
        joint_cam = world2cam(
            joint_world.transpose(1, 0), camrot, campos.reshape(3, 1)
        ).transpose(1, 0)

    return (x0, y0, x1, y1), bbox, pts_2d, joint_cam, joint_valid, retval_camera


def load_crop_img(
    path, bbox, pts_2d, joint_world, joint_valid, retval_camera, order="RGB"
):

    img = cv2.imread(path, cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)
    if not isinstance(img, np.ndarray):
        raise IOError("Fail to read %s" % path)

    if order == "RGB":
        img = img[:, :, ::-1].copy()

    img = img.astype(np.float32)

    (
        (x0, y0, x1, y1),
        bbox,
        pts_2d,
        joint_cam,
        joint_valid,
        retval_camera,
    ) = update_params_after_crop(
        bbox, pts_2d, joint_world, joint_valid, retval_camera, img.shape[:2]
    )
    assert (
        sum(joint_valid) >= 10
    ), f"sum(joint_valid): {sum(joint_valid)}, path: {path}, joint_valid: {joint_valid}"
    # crop
    img = Image.fromarray(img.astype(np.uint8))
    img = img.crop([x0, y0, x1, y1])
    img = np.asarray(img)
    assert (
        img.shape[0] > 50 and img.shape[1] > 50
    ), f"img.shape: {img.shape}, path: {path}, bbox: {x0}, {y0}, {bbox[2]}"

    return img, bbox, pts_2d, joint_cam, joint_valid, retval_camera


def load_skeleton(path, joint_num):

    # load joint_world info (name, parent_id)
    skeleton = [{} for _ in range(joint_num)]
    with open(path) as fp:
        for line in fp:
            if line[0] == "#":
                continue
            splitted = line.split(" ")
            joint_name, joint_id, joint_parent_id = splitted
            joint_id, joint_parent_id = int(joint_id), int(joint_parent_id)
            skeleton[joint_id]["name"] = joint_name
            skeleton[joint_id]["parent_id"] = joint_parent_id
    # save child_id
    for i in range(len(skeleton)):
        joint_child_id = []
        for j in range(len(skeleton)):
            if skeleton[j]["parent_id"] == i:
                joint_child_id.append(j)
        skeleton[i]["child_id"] = joint_child_id

    return skeleton


def get_aug_config():
    trans_factor = 0.15
    scale_factor = 0.25
    rot_factor = 45
    color_factor = 0.2

    trans = [
        np.random.uniform(-trans_factor, trans_factor),
        np.random.uniform(-trans_factor, trans_factor),
    ]
    scale = np.clip(np.random.randn(), -1.0, 1.0) * scale_factor + 1.0
    rot = (
        np.clip(np.random.randn(), -2.0, 2.0) * rot_factor
        if random.random() <= 0.6
        else 0
    )
    do_flip = random.random() <= 0.5
    c_up = 1.0 + color_factor
    c_low = 1.0 - color_factor
    color_scale = np.array(
        [
            random.uniform(c_low, c_up),
            random.uniform(c_low, c_up),
            random.uniform(c_low, c_up),
        ]
    )

    return trans, scale, rot, do_flip, color_scale


def augmentation(
    img, bbox, joint_coord, joint_valid, hand_type, mode, joint_type, no_aug=False
):
    img = img.copy()
    joint_coord = joint_coord.copy()
    hand_type = hand_type.copy()

    original_img_shape = img.shape
    joint_num = len(joint_coord)

    if mode == "train" and not no_aug:
        trans, scale, rot, do_flip, color_scale = get_aug_config()
    else:
        trans, scale, rot, do_flip, color_scale = (
            [0, 0],
            1.0,
            0.0,
            False,
            np.array([1, 1, 1]),
        )
        # trans, scale, rot, do_flip, color_scale = get_aug_config()

    bbox[0] = bbox[0] + bbox[2] * trans[0]
    bbox[1] = bbox[1] + bbox[3] * trans[1]
    img, trans, inv_trans = generate_patch_image(
        img, bbox, do_flip, scale, rot, cfg.input_img_shape
    )
    img = np.clip(img * color_scale[None, None, :], 0, 255)

    if do_flip:
        joint_coord[:, 0] = original_img_shape[1] - joint_coord[:, 0] - 1
        joint_coord[joint_type["right"]], joint_coord[joint_type["left"]] = (
            joint_coord[joint_type["left"]].copy(),
            joint_coord[joint_type["right"]].copy(),
        )
        joint_valid[joint_type["right"]], joint_valid[joint_type["left"]] = (
            joint_valid[joint_type["left"]].copy(),
            joint_valid[joint_type["right"]].copy(),
        )
        hand_type[0], hand_type[1] = hand_type[1].copy(), hand_type[0].copy()
    for i in range(joint_num):
        joint_coord[i, :2] = trans_point2d(joint_coord[i, :2], trans)
        joint_valid[i] = (
            joint_valid[i]
            * (joint_coord[i, 0] >= 0)
            * (joint_coord[i, 0] < cfg.input_img_shape[1])
            * (joint_coord[i, 1] >= 0)
            * (joint_coord[i, 1] < cfg.input_img_shape[0])
        )

    return img, joint_coord, joint_valid, hand_type, inv_trans


def transform_input_to_output_space(
    joint_coord, joint_valid, rel_root_depth, root_valid, root_joint_idx, joint_type
):
    # transform to output heatmap space
    joint_coord = joint_coord.copy()
    joint_valid = joint_valid.copy()

    joint_coord[:, 0] = (
        joint_coord[:, 0] / cfg.input_img_shape[1] * cfg.output_hm_shape[2]
    )
    joint_coord[:, 1] = (
        joint_coord[:, 1] / cfg.input_img_shape[0] * cfg.output_hm_shape[1]
    )
    joint_coord[joint_type["right"], 2] = (
        joint_coord[joint_type["right"], 2] - joint_coord[root_joint_idx["right"], 2]
    )
    joint_coord[joint_type["left"], 2] = (
        joint_coord[joint_type["left"], 2] - joint_coord[root_joint_idx["left"], 2]
    )

    joint_coord[:, 2] = (
        (joint_coord[:, 2] / (cfg.bbox_3d_size / 2) + 1) / 2.0 * cfg.output_hm_shape[0]
    )
    joint_valid = joint_valid * (
        (joint_coord[:, 2] >= 0) * (joint_coord[:, 2] < cfg.output_hm_shape[0])
    ).astype(np.float32)
    rel_root_depth = (
        (rel_root_depth / (cfg.bbox_3d_size_root / 2) + 1)
        / 2.0
        * cfg.output_root_hm_shape
    )
    root_valid = root_valid * (
        (rel_root_depth >= 0) * (rel_root_depth < cfg.output_root_hm_shape)
    ).astype(np.float32)

    return joint_coord, joint_valid, rel_root_depth, root_valid


def get_bbox(joint_img, joint_valid):
    x_img = joint_img[:, 0][joint_valid == 1]
    y_img = joint_img[:, 1][joint_valid == 1]
    xmin = min(x_img)
    ymin = min(y_img)
    xmax = max(x_img)
    ymax = max(y_img)

    x_center = (xmin + xmax) / 2.0
    width = xmax - xmin
    xmin = x_center - 0.5 * width * 1.2
    xmax = x_center + 0.5 * width * 1.2

    y_center = (ymin + ymax) / 2.0
    height = ymax - ymin
    ymin = y_center - 0.5 * height * 1.2
    ymax = y_center + 0.5 * height * 1.2

    bbox = np.array([xmin, ymin, xmax - xmin, ymax - ymin]).astype(np.float32)
    return bbox


def process_bbox(bbox, original_img_shape, scale=1.25):

    # aspect ratio preserving bbox
    w = bbox[2]
    h = bbox[3]
    c_x = bbox[0] + w / 2.0
    c_y = bbox[1] + h / 2.0
    aspect_ratio = cfg.input_img_shape[1] / cfg.input_img_shape[0]
    if w > aspect_ratio * h:
        h = w / aspect_ratio
    elif w < aspect_ratio * h:
        w = h * aspect_ratio
    bbox[2] = w * scale
    bbox[3] = h * scale
    bbox[0] = c_x - bbox[2] / 2.0
    bbox[1] = c_y - bbox[3] / 2.0

    return bbox


def generate_patch_image(cvimg, bbox, do_flip, scale, rot, out_shape):
    img = cvimg.copy()
    img_height, img_width, img_channels = img.shape

    bb_c_x = float(bbox[0] + 0.5 * bbox[2])
    bb_c_y = float(bbox[1] + 0.5 * bbox[3])
    bb_width = float(bbox[2])
    bb_height = float(bbox[3])

    if do_flip:
        img = img[:, ::-1, :]
        bb_c_x = img_width - bb_c_x - 1

    trans = gen_trans_from_patch_cv(
        bb_c_x, bb_c_y, bb_width, bb_height, out_shape[1], out_shape[0], scale, rot
    )
    try:
        img_patch = cv2.warpAffine(
            img, trans, (int(out_shape[1]), int(out_shape[0])), flags=cv2.INTER_LINEAR
        )
    except:
        print(img.shape, (int(out_shape[1]), int(out_shape[0])))
        raise Exception()
    img_patch = img_patch.astype(np.float32)
    inv_trans = gen_trans_from_patch_cv(
        bb_c_x,
        bb_c_y,
        bb_width,
        bb_height,
        out_shape[1],
        out_shape[0],
        scale,
        rot,
        inv=True,
    )

    return img_patch, trans, inv_trans


def rotate_2d(pt_2d, rot_rad):
    x = pt_2d[0]
    y = pt_2d[1]
    sn, cs = np.sin(rot_rad), np.cos(rot_rad)
    xx = x * cs - y * sn
    yy = x * sn + y * cs
    return np.array([xx, yy], dtype=np.float32)


def gen_trans_from_patch_cv(
    c_x, c_y, src_width, src_height, dst_width, dst_height, scale, rot, inv=False
):
    # augment size with scale
    src_w = src_width * scale
    src_h = src_height * scale
    src_center = np.array([c_x, c_y], dtype=np.float32)

    # augment rotation
    rot_rad = np.pi * rot / 180
    src_downdir = rotate_2d(np.array([0, src_h * 0.5], dtype=np.float32), rot_rad)
    src_rightdir = rotate_2d(np.array([src_w * 0.5, 0], dtype=np.float32), rot_rad)

    dst_w = dst_width
    dst_h = dst_height
    dst_center = np.array([dst_w * 0.5, dst_h * 0.5], dtype=np.float32)
    dst_downdir = np.array([0, dst_h * 0.5], dtype=np.float32)
    dst_rightdir = np.array([dst_w * 0.5, 0], dtype=np.float32)

    src = np.zeros((3, 2), dtype=np.float32)
    src[0, :] = src_center
    src[1, :] = src_center + src_downdir
    src[2, :] = src_center + src_rightdir

    dst = np.zeros((3, 2), dtype=np.float32)
    dst[0, :] = dst_center
    dst[1, :] = dst_center + dst_downdir
    dst[2, :] = dst_center + dst_rightdir

    if inv:
        trans = cv2.getAffineTransform(np.float32(dst), np.float32(src))
    else:
        trans = cv2.getAffineTransform(np.float32(src), np.float32(dst))

    trans = trans.astype(np.float32)
    return trans


def trans_point2d(pt_2d, trans):
    src_pt = np.array([pt_2d[0], pt_2d[1], 1.0]).T
    dst_pt = np.dot(trans, src_pt)
    return dst_pt[0:2]
